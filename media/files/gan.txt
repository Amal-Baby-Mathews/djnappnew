A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative AI.[1][2] The concept was initially developed by Ian Goodfellow and his colleagues in June 2014.[3] In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.

Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning,[4] fully supervised learning,[5] and reinforcement learning.[6]

The core idea of a GAN is based on the "indirect" training through the discriminator, another neural network that can tell how "realistic" the input seems, which itself is also being updated dynamically.[7] This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.

GANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.

Definition
Mathematical
The original GAN is defined as the following game:[3]

Each probability space 
(
Ω
,
�
ref
)
{\displaystyle (\Omega ,\mu _{\text{ref}})} defines a GAN game.

There are 2 players: generator and discriminator.

The generator's strategy set is 
�
(
Ω
)
{\displaystyle {\mathcal {P}}(\Omega )}, the set of all probability measures 
�
�
{\displaystyle \mu _{G}} on 
Ω{\displaystyle \Omega }.

The discriminator's strategy set is the set of Markov kernels 
�
�
:
Ω
→
�
[
0
,
1
]
{\displaystyle \mu _{D}:\Omega \to {\mathcal {P}}[0,1]}, where 
�
[
0
,
1
]
{\displaystyle {\mathcal {P}}[0,1]} is the set of probability measures on 
[
0
,
1
]
{\displaystyle [0,1]}.

The GAN game is a zero-sum game, with objective function

�
(
�
�
,
�
�
)
:=
�
�
∼
�
ref
,
�
∼
�
�
(
�
)
[
ln
⁡
�
]
+
�
�
∼
�
�
,
�
∼
�
�
(
�
)
[
ln
⁡
(
1
−
�
)
]
.
{\displaystyle L(\mu _{G},\mu _{D}):=\mathbb {E} _{x\sim \mu _{\text{ref}},y\sim \mu _{D}(x)}[\ln y]+\mathbb {E} _{x\sim \mu _{G},y\sim \mu _{D}(x)}[\ln(1-y)].}
The generator aims to minimize the objective, and the discriminator aims to maximize the objective.
The generator's task is to approach 
�
�
≈
�
ref
{\displaystyle \mu _{G}\approx \mu _{\text{ref}}}, that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator's task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.

In practice
The generative network generates candidates while the discriminative network evaluates them.[3] The contest operates in terms of data distributions. Typically, the generative network learns to map from a latent space to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., "fool" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).[3][8]

A known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples.[9] When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a convolutional neural network.

Relation to other statistical machine learning methods
GANs are implicit generative models,[10] which means that they do not explicitly model the likelihood function nor provide a means for finding the latent variable corresponding to a given sample, unlike alternatives such as flow-based generative model.


Main types of deep generative models that perform maximum likelihood estimation[11]
Compared to fully visible belief networks such as WaveNet and PixelRNN and autoregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network.

Compared to Boltzmann machines and nonlinear ICA, there is no restriction on the type of function used by the network.

Since neural networks are universal approximators, GANs are asymptotically consistent. Variational autoencoders might be universal approximators, but it is not proven as of 2017.[11]

Mathematical properties
Measure-theoretic considerations
This section provides some of the mathematical theory behind these methods.

In modern probability theory based on measure theory, a probability space also needs to be equipped with a σ-algebra. As a result, a more rigorous definition of the GAN game would make the following changes:

Each probability space 
(
Ω
,
�
,
�
ref
)
{\displaystyle (\Omega ,{\mathcal {B}},\mu _{\text{ref}})} defines a GAN game.

The generator's strategy set is 
�
(
Ω
,
�
)
{\displaystyle {\mathcal {P}}(\Omega ,{\mathcal {B}})}, the set of all probability measures 
�
�
{\displaystyle \mu _{G}} on the measure-space 
(
Ω
,
�
)
{\displaystyle (\Omega ,{\mathcal {B}})}.

The discriminator's strategy set is the set of Markov kernels 
�
�
:
(
Ω
,
�
)
→
�
(
[
0
,
1
]
,
�
(
[
0
,
1
]
)
)
{\displaystyle \mu _{D}:(\Omega ,{\mathcal {B}})\to {\mathcal {P}}([0,1],{\mathcal {B}}([0,1]))}, where 
�
(
[
0
,
1
]
)
{\displaystyle {\mathcal {B}}([0,1])} is the Borel σ-algebra on 
[
0
,
1
]
{\displaystyle [0,1]}.

Since issues of measurability never arise in practice, these will not concern us further.

Choice of the strategy set
In the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels 
�
�
:
Ω
→
�
[
0
,
1
]
{\displaystyle \mu _{D}:\Omega \to {\mathcal {P}}[0,1]}, and the strategy set for the generator contains arbitrary probability distributions 
�
�
{\displaystyle \mu _{G}} on 
Ω{\displaystyle \Omega }.

However, as shown below, the optimal discriminator strategy against any 
�
�
{\displaystyle \mu _{G}} is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions 
�
:
Ω
→
[
0
,
1
]
{\displaystyle D:\Omega \to [0,1]}. In most applications, 
�
{\displaystyle D} is a deep neural network function.

As for the generator, while 
�
�
{\displaystyle \mu _{G}} could theoretically be any computable probability distribution, in practice, it is usually implemented as a pushforward: 
�
�
=
�
�
∘
�
−
1
{\displaystyle \mu _{G}=\mu _{Z}\circ G^{-1}}. That is, start with a random variable 
�
∼
�
�
{\displaystyle z\sim \mu _{Z}}, where 
�
�
{\displaystyle \mu _{Z}} is a probability distribution that is easy to compute (such as the uniform distribution, or the Gaussian distribution), then define a function 
�
:
Ω
�
→
Ω{\displaystyle G:\Omega _{Z}\to \Omega }. Then the distribution 
�
�
{\displaystyle \mu _{G}} is the distribution of 
�
(
�
)
{\displaystyle G(z)}.

Consequently, the generator's strategy is usually defined as just 
�
{\displaystyle G}, leaving 
�
∼
�
�
{\displaystyle z\sim \mu _{Z}} implicit. In this formalism, the GAN game objective is

�
(
�
,
�
)
:=
�
�
∼
�
ref
[
ln
⁡
�
(
�
)
]
+
�
�
∼
�
�
[
ln
⁡
(
1
−
�
(
�
(
�
)
)
)
]
.
{\displaystyle L(G,D):=\mathbb {E} _{x\sim \mu _{\text{ref}}}[\ln D(x)]+\mathbb {E} _{z\sim \mu _{Z}}[\ln(1-D(G(z)))].}
Generative reparametrization
The GAN architecture has two main components. One is casting optimization into a game, of form 
min
�
max
�
�
(
�
,
�
)
{\displaystyle \min _{G}\max _{D}L(G,D)}, which is different from the usual kind of optimization, of form 
min
�
�
(
�
)
{\displaystyle \min _{\theta }L(\theta )}. The other is the decomposition of 
�
�
{\displaystyle \mu _{G}} into 
�
�
∘
�
−
1
{\displaystyle \mu _{Z}\circ G^{-1}}, which can be understood as a reparametrization trick.

To see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with "intractable probabilistic computations that arise in maximum likelihood estimation and related strategies".[3]

At the same time, Kingma and Welling[12] and Rezende et al.[13] developed the same idea of reparametrization into a general stochastic backpropagation method. Among its first applications was the variational autoencoder.